{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00eb1458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting page 1, Status Code: 200\n",
      "Requesting page 2, Status Code: 200\n",
      "Requesting page 3, Status Code: 200\n",
      "Requesting page 4, Status Code: 200\n",
      "Requesting page 5, Status Code: 200\n",
      "No links found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Base URL for the API\n",
    "url = \"https://www.marksandspencer.com/c/food-and-wine/cooking/recipes/search/\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"accept\": \"application/json, text/plain, */*\",\n",
    "    \"content-type\": \"application/json;charset=UTF-8\",\n",
    "    \"x-requested-with\": \"XMLHttpRequest\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\",\n",
    "}\n",
    "\n",
    "# Function to scrape links\n",
    "def scrape_links(page_number, page_size=40):\n",
    "    # Construct the JSON payload\n",
    "    data = {\n",
    "        \"Page\": page_number,\n",
    "        \"PageSize\": page_size,\n",
    "        \"Query\": \"\",\n",
    "        \"Filter\": [\n",
    "            {\"Operation\": \"AND\", \"Sublist\": []},\n",
    "            {\"Operation\": \"OR\", \"Sublist\": []}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    print(f\"Requesting page {page_number}, Status Code: {response.status_code}\")\n",
    "    if response.status_code == 200: #If links not working it will give statues code 405\n",
    "        return response.json()  # Return the JSON response\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page_number}: {response.status_code}, Response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract links\n",
    "def extract_links(data):\n",
    "    if data and \"Results\" in data:\n",
    "        links = []\n",
    "        for item in data[\"Results\"]:\n",
    "            links.append(item.get(\"Url\"))  # Adjust the key as per your findings\n",
    "        return links\n",
    "    return []\n",
    "\n",
    "# Main scraping loop\n",
    "all_links = []\n",
    "total_pages = 5  # Adjust this based on how many pages you want to scrape\n",
    "\n",
    "for page in range(1, total_pages + 1):\n",
    "    data = scrape_links(page)\n",
    "    links = extract_links(data)\n",
    "    all_links.extend(links)\n",
    "\n",
    "# Print the scraped links\n",
    "if all_links:\n",
    "    print(\"Scraped Links:\")\n",
    "    for link in all_links:\n",
    "        print(link)\n",
    "else:\n",
    "    print(\"No links found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5de025",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service('C:/drivers/chromedriver.exe')  # Make sure this path is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e087bc9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize the WebDriver (update the path)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/path/to/chromedriver.exe\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Update this path\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchrome_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Replace with the URL of the page you want to scrape\u001b[39;00m\n\u001b[0;32m     19\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.marksandspencer.com/c/food-and-wine/cooking/search/?filters=[]#/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\oyku_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\oyku_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:51\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvendor_prefix \u001b[38;5;241m=\u001b[39m vendor_prefix\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[43mDriverFinder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\oyku_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:44\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[1;34m(service, options)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to locate or obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;241m.\u001b[39mcapabilities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[1;31mNoSuchDriverException\u001b[0m: Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run headless if you don't need a UI\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize the WebDriver (update the path)\n",
    "service = Service('C:/path/to/chromedriver.exe')  # Update this path\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Replace with the URL of the page you want to scrape\n",
    "url = \"https://www.marksandspencer.com/c/food-and-wine/cooking/search/?filters=[]#/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Give the page time to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Scroll and collect links\n",
    "collected_links = set()\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Find all links on the current page\n",
    "        links = driver.find_elements(By.TAG_NAME, 'a')\n",
    "        for link in links:\n",
    "            href = link.get_attribute('href')\n",
    "            if href:\n",
    "                collected_links.add(href)\n",
    "\n",
    "        # Scroll down to the bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait for new content to load\n",
    "\n",
    "        # Calculate new height and compare to last height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:  # If no new content is loaded, break the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(\"Element not found, breaking the loop.\")\n",
    "        break\n",
    "\n",
    "# Output the collected links\n",
    "for link in collected_links:\n",
    "    print(link)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
